%-------------------------------------------------------------------------------
% A Review of Classic Edge Detectors - v3.3
% by Haldo SpontÃ³n & Juan Cardelino
% IPOL 2015
%-------------------------------------------------------------------------------

\documentclass{ipol}
%\ipolSetID{arced}
\ipolSetTitle{A Review of Classic Edge Detectors}
\ipolSetAuthors{Haldo Spont\'on$^1$, Juan Cardelino$^2$}
\ipolSetAffiliations{%
$^1$ IIE, UdelaR, Uruguay (\texttt{haldos@fing.edu.uy})\\
$^2$ IIE, UdelaR, Uruguay (\texttt{juanc@fing.edu.uy})}

\usepackage{hyperref,verbatim,graphicx,amsmath,amssymb,amssymb,dsfont}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{sidecap}
\usepackage[hang,center]{subfigure}
\usepackage[table]{xcolor}
\usepackage{multicol}
\usepackage{listings}
\usepackage{color}
\usepackage{calc}
\usepackage{array}
%\usepackage{algorithm}
\usepackage{algorithmic}
\newtheorem{theorem}{Theorem}
\numberwithin{equation}{section}
\numberwithin{table}{section}
%\numberwithin{figure}{section}
\usepackage{marginnote}
\newcounter{mynote}% a new counter for use in margin notes
\usepackage[multidot]{grffile}
\usepackage{jfc}

\newcommand{\demourl}{http://dev.ipol.im/~juanc/ipol_demo/sc_edges/}

\begin{document}

\lstset{
	backgroundcolor=\color[rgb]{0.94,0.94,0.94},
    tabsize=4,
    inputencoding=utf8x,
         extendedchars=\true,
         language=C,
         basicstyle=\scriptsize,
                 showtabs=false,
        showspaces=false,
        showstringspaces=false,
        identifierstyle=\ttfamily,
        keywordstyle=\color[rgb]{0,0,1},
        commentstyle=\color[rgb]{0.133,0.545,0.133},
        stringstyle=\color[rgb]{0.627,0.126,0.941},
}
% Square cells table
\newlength\celldim \newlength\fontheight \newlength\extraheight
\newcounter{sqcolumns}
\newcolumntype{S}{ @{}
  >{\centering \rule[-0.5\extraheight]{0pt}{\fontheight + \extraheight}}
  p{\celldim} @{} }
\newcolumntype{Z}{ @{} >{\centering} p{\celldim} @{} }
\newenvironment{squarecells}[1]
  {\setlength\celldim{2em}%
   \settoheight\fontheight{A}%
   \setlength\extraheight{\celldim - \fontheight}%
   \setcounter{sqcolumns}{#1 - 1}%
   \begin{tabular}{|S|*{\value{sqcolumns}}{Z|}}\hline}
% squarecells tabular goes here
  {\end{tabular}}
\newcommand\nline{\tabularnewline\hline}

%-------------------------------------------------------------------------------

\begin{abstract}
In this paper some of the classic alternatives for edge detection in digital images are studied. The main idea 
of edge detection algorithms is to find where abrupt changes in the intensity of an image have occurred. 
The first family of algorithms reviewed in this work uses the first derivative to find the changes of intensity, 
such as Sobel, Prewitt and Roberts. In the second reviewed family, second derivatives are used, for example in algorithms 
like Marr-Hildreth and Haralick. \\
Obtained results are analyzed from a qualitative point of view (perceptual) and from a quantitative 
point of view (number of operations, execution time), considering different ways to convolve an image with a kernel (step required in some of the algorithms).
\end{abstract}

%-------------------------------------------------------------------------------

\begin{ipolCode}
For all the reviewed algorithms, an open source C implementation is provided which can be downloaded from 
the IPOL publication of this article. An 
\href{\demourl}{online demonstration}%\footnote{\url{http://dev.ipol.im/~juanc/ipol_demo/sc_edges/}} 
is also available, where you can test and reproduce our results.
\end{ipolCode}

% You can also follow this code project in this \href{git://github.com/haldos/edges.git}{GIT repository} 
% \href{http://iie.fing.edu.uy/~haldos/downloads/edge_detectors_v0.1.tar.gz}{here}

%%-------------------------------------------------------------------------------

%\begin{ipolSupp}
%\end{ipolSupp}

%-------------------------------------------------------------------------------

\section{Introduction}
\label{sec:intro}

Edge detection is one of the oldest and most basic operations in image processing, which is often used as a basic building block for more complex algorithms. The basic idea of edge detection is to detect abrupt changes in image intensity. 
Detecting those changes can be accomplished using first or second order derivatives. \\

In the 70's, edge detection methods were implemented using small operators 
(such as Sobel masks), attempting to compute an approximation of the
first derivative of the image \cite{Gonzalez2007Digital}. Section \ref{sec:first} describes such algorithms 
and serves as an introduction to a more sophisticated 
analysis of the edge detection process.

% en este parrafo, puede ser cambiar trough por valley
In 1980 Marr and Hildreth \cite{segm:edge_region:marr:84:digital_step} argued that intensity changes are not independent 
of image scale, so edge detection requires the use of different size 
operators. They also argued that a sudden intensity change will be seen 
as a peak (or valley) in the first derivative or, equivalently, as a zero 
crossing in the second derivative. This algorithm is presented in Section \ref{sec:second}. 
Haralick's algorithm \cite{bb20239} is an alternative approach based on the second derivative 
which is also reviewed in Section \ref{sec:second}. This algorithm has the particularity of 
proposing a model to locally approximate the image around a point; then, using this model, 
an approximation to the second derivative of the image can be calculated analytically and 
finding edges is achieved by imposing a condition over the model parameters. 

The objective of this work is to provide reproducible implementations of the abovementioned algorithms, along with a comprehensive quantitative evaluation of the behaviour algorithms with respect to the parameters. Quantitative benchmarks are outside the scope of this work and will be addressed in future work.
In addition, we will focus on low-level edge detection algorithms, which means that they will output a disconnected and unordered set of edgels (individual pixel facets where boundaries occur). Algorithms that perform edge integration into objects boundaries are of higher level of abstraction and not considered in this work.

Along with this paper, a detailed and well commented source code is presented, which 
implements the described algorithms. In section \ref{sec:appendix1} some common mathematical developments are presented. 
%A commented explanation of the source code can be found in section \ref{sec:appendix2}. This work also provides tools for code documentation 
%(see section \ref{sec:appendix2}). 
Results of the implemented algorithms are presented in Section \ref{sec:results}, along with examples 
to compare their performance. Conclusions are detailed in Section \ref{sec:conclusions}.

\nocite{IPOL}

%-------------------------------------------------------------------------------

\section{Algorithms based on the first derivative}
\label{sec:first}

The algorithms based on first derivatives studied in this paper share a common structure, which only differs in the type of filtering used to compute those derivatives. Figure \ref{fig:blockdiagram1} shows a block diagram of that common structure. \\

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{blockdiagram1.pdf}
	\caption{Block diagram of first derivative edge detection algorithms.}
	\label{fig:blockdiagram1}
\end{figure}

The usual tool to find the magnitude and direction of the
intensity changes of an image $f$ is the gradient operator (denoted as $\nabla$), defined 
as the vector
\begin{equation}
	\nabla f = 
				\begin{bmatrix} 
					f_x \\ f_y
				\end{bmatrix}
	=				
				\begin{bmatrix} 
					\cfrac{\partial f}{\partial x} \\ \cfrac{\partial f}{\partial y} \\
				\end{bmatrix}.
\end{equation}

The magnitude ($M$) and direction ($\alpha$) of the gradient vector $\nabla f$ at location $(x,y)$
are calculated as
\begin{equation}
\label{eq:mag_alpha}
	\begin{cases}
		M(x,y) = \sqrt{f_x^2 + f_y^2} \\
		\alpha(x,y) = \tan^{-1} \left( \dfrac{f_y}{f_x} \right) .
	\end{cases}
\end{equation}

The direction of an edge at an arbitrary location $(x,y)$ of the image is 
orthogonal to the direction $\alpha(x,y)$ of the gradient vector.

To obtain the gradient, the partial derivatives $\partial f/\partial x$ and $\partial f/\partial y$ 
need to be computed at every pixel in the image. When dealing with digital images, numerical approximations 
of these derivatives are computed in a neighborhood of each point. In the following,
the methods of Roberts, Prewitt and Sobel will be studied, whose main difference is how they perform this calculation. 

%-------------------------------------------------------------------------------

\subsection{The \textit{Roberts} operators}

The Roberts edge detector was introduced in 1963 by L.G. Roberts in the context of 3D reconstrution \cite{im_proc:segmentation:roberts:1963:boundary_extraction}, and it was based on the computation of the first derivative of the image. The most usual approach to approximate the first derivative is to use a the first order Taylor expansion with a small value of $h$. Thus $f'(x)$ is computed as
\begin{equation}
	f'(x) \simeq \frac{f(x+h) - f(x)}{h}.\\
\end{equation}
Digital images are commonly seen as a discretization of a continuous image, where a pixel is evenly sampled on a grid. If we denote the grid sizes by $\Delta x$ and $\Delta y$, the continuous coordinates $x$  and $y$ can be written as $x=i\Delta x$ and $y=i\Delta y$. When no information about the spatial sampling is available, the size of the grid it is commonly assumed to be $\Delta x=\Delta y=1$.\\
Thus, in the discrete space the first derivative of the image is computed as:
\begin{equation}
\label{eq:roberts1}
	f_x = \frac{\partial f(x,y)}{\partial x} \cong f(i+1,j) - f(i,j)
\end{equation}
and
\begin{equation}
\label{eq:roberts2}
	f_y = \frac{\partial f(x,y)}{\partial y} \cong f(i,j+1) - f(i,j).
\end{equation}

Equations \ref{eq:roberts1} and \ref{eq:roberts2} can be implemented for all values of $x$ and $y$ by filtering the image $f(x,y)$ with the 1-D masks shown in Figure \ref{fig:1dmasks}. However, in order to be able to compute diagonal edges, 2-D masks are needed. \\
The \textit{Roberts operators} are one of the earliest 
attempts to use 2-D masks for this purpose. These operators are based on computing the diagonal differences implemented by filtering an image with the masks in Figure \ref{fig:roberts}. By convention 
in these figures, x-coordinates grow from left to right and y-coordinates grow top-down. It is also 
usual to scale the mask values, in order to have gain equal to $1$. \\

% la primer figura es una forma simple de calcular las derivadas, pero roberst, en [referenfcia]
% propone calcularlos como en la segunda figura. Nota: cambiar signos.

%% VER NORMALIZACION

\begin{figure}[h!]
	\centering
	\begin{squarecells}{1}
		-1   \nline
		1  \nline
	\end{squarecells}
	\quad
	\begin{squarecells}{2}
		-1 & 1   \nline
	\end{squarecells}
	\caption{One-dimensional masks used to implement equations \ref{eq:roberts1} and \ref{eq:roberts2}.}
	\label{fig:1dmasks}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{squarecells}{2}
		-1 &  0  \nline
		0 & 1  \nline
	\end{squarecells}
	\quad
	\begin{squarecells}{2}
		0  & -1  \nline
		1 & 0  \nline
	\end{squarecells}
	\caption{\textit{Roberts cross-gradient} 2-D masks.}
	\label{fig:roberts}
\end{figure}

Figure \ref{fig:1dmasks} shows the simplest way to compute derivatives, but Roberts \cite{im_proc:segmentation:roberts:1963:boundary_extraction} proposes
to compute them as shown in Figure \ref{fig:roberts}. In order to use the same convolution code for all algorithms, our implementation uses $3\times3$ matrices, adding a row and a column of zeros to the matrices in Figure \ref{fig:roberts}, which produces the same result.

%-------------------------------------------------------------------------------

\subsection{The \textit{Prewitt} operators}\label{sec:first:prewitt}

% agregar referencia

Masks of size $2\times2$, although conceptually simple, are not symmetrical with respect to the central points. 
Having symmetrical edges is a desirable property and can only be achieved with oddly sized masks, the smallest 
of them being the 3x3. These masks provide more information to find the direction of the edges, because they take 
into account information on opposite sides of the central point. 

The simplest digital approximation of the partial derivatives using masks of size $3\times3$ is obtained 
by taking the difference between the third and first rows (or columns) of the $3\times3$ region. The
difference between the third and first rows approximates the derivative in the x-direction, and 
the difference between the third and first columns approximates the derivative in the y-direction.
These approximations can be implemented by filtering the image with the two masks shown in Figure \ref{fig:prewitt}.
These masks are called \textit{Prewitt operators} \cite{im_proc:segmentation:prewitt:1970:object_enhancement}. 

\begin{figure}[h!]
	\centering
	\begin{squarecells}{3}
		$-\frac{1}{3}$ 	& $-\frac{1}{3}$ 	& $-\frac{1}{3}$	\nline
		0 			& 0			& 0			\nline
		$\frac{1}{3}$ 	& $\frac{1}{3}$ 	& $\frac{1}{3}$	\nline
	\end{squarecells}
	\quad
	\begin{squarecells}{3}
		$-\frac{1}{3}$ 	& 0 	& $\frac{1}{3}$	\nline
		$-\frac{1}{3}$	& 0	& $\frac{1}{3}$	\nline
		$-\frac{1}{3}$ 	& 0 	& $\frac{1}{3}$	\nline
	\end{squarecells}
	\caption{Normalized \textit{Prewitt} 2-D masks of size $3\times3$.}
	\label{fig:prewitt}
\end{figure}

The left mask can be constructed (up to a scale factor) as the convolution of two filters: a vertical derivative 
$[-1\ 0\ 1]^T$ and an horizontal moving average $[1\ 1\ 1]$. The same reasoning could be applied to the right mask. Hence, these operators can be interpreted as the consecutive application of an horizontal low pass filter with a vertical derivative filter, and viceversa. Thus, they show smoothing properties in the direction orthogonal to the gradient.

%-------------------------------------------------------------------------------

\subsection{The \textit{Sobel} operators}\label{sec:first:sobel}

\textit{Sobel operators} are a slight variation of the Prewitt operators which use more weight on the central coefficients of the masks. It can be shown that using more weight in the center location provides better image smoothing. This variation is implemented using masks shown in Figure \ref{fig:sobel}. 

\begin{figure}[h!]
	\centering
	\begin{squarecells}{3}
		$-\frac{1}{4}$ 	& $-\frac{1}{2}$ 	& $-\frac{1}{4}$	\nline
		0 			& 0			& 0			\nline
		$\frac{1}{4}$ 	& $\frac{1}{2}$ 	& $\frac{1}{4}$	\nline
	\end{squarecells}
	\quad
	\begin{squarecells}{3}
		$-\frac{1}{4}$ 	& 0 	& $\frac{1}{4}$	\nline
		$-\frac{1}{2}$	& 0	& $\frac{1}{2}$	\nline
		$-\frac{1}{4}$ 	& 0 	& $\frac{1}{4}$	\nline
	\end{squarecells}
	\caption{\textit{Sobel} 2-D masks of size $3\times3$.}
	\label{fig:sobel}
\end{figure}

Sobel masks can be seen (up to a  scale factor) as the convolution of a vertical derivation mask 
$[-1\ 0\ 1]^T$ with an horizontal smoothing filter $[1\ 2\ 1]$ (closer to a Gaussian response than Prewitt), and vice versa. 
Hence, these operators have better smoothing properties, as mentioned in the preceding paragraph. \\

The computational cost of applying Prewitt and Sobel masks is exactly the same. Thus, it is preferable to use Sobel operators, because edges are better localized, and its filters are also less aliased, because of the weighted shape of the kernel.

%-------------------------------------------------------------------------------

\subsection{Computation of the edges}\label{sec:first:sobel:computation}

As mentioned before, edges can be seen as abrupt changes in intensity, which correspond high values of the gradient.
An example of this behavior is shown in Figure \ref{fig:profiles3d}, where gradient was computed using Sobel operators. 

Then, once the respective operators are applied, an approximation of the gradient (stored in two matrices) 
is obtained, containing the approximation of the partial derivatives $f_x$ and $f_y$. Gradient magnitude 
image $M$ is calculated using the equation \ref{eq:mag_alpha} (Figure \ref{fig:profiles3d-c}). 

Finally, the edges image is obtained by thresholding the gradient magnitude image, i.e. for a pixel at position $i,j$ in the image the algorithm computes
\begin{equation*}
	\mbox{edges}[i,j] = \begin{cases} 1,& \mbox{if}\ M[i,j]\geq\mbox{th} \\
									0,& \mbox{if}\ M[i,j]<\mbox{th}
					  \end{cases}
\end{equation*}
where $\emph{th}$ is the threshold. A black and white image is obtained, in which edge points are indicated in white (see Figure \ref{fig:thresholding}). 
It is noted that different thresholds lead to different results: thicker or more edges for smaller thresholds, fewer and sparser edges for larger thresholds. This threshold, and the others mentioned below, are defined as a percentage of the maximum value 
of the gradient image. The advantage of this approach is to adapt the threshold to the dynamic range of the image. 
Therefore, the parameter $threshold$ in the algorithms takes values ââbetween $0$ and $1$.


\begin{figure}[t!]
	\centering
	\subfigure[Grayscale image.]{\label{fig:profiles3d-a}\includegraphics[width=0.3\textwidth]{molino_crop_bw.jpg}}
	
	\subfigure[Horizontal derivative $f_x$.]{\label{fig:profiles3d-b}\includegraphics[width=0.3\textwidth]{gradient_image_x.png}}
	\quad
	\subfigure[Vertical derivative $f_y$.]{\label{fig:profiles3d-c}\includegraphics[width=0.3\textwidth]{gradient_image_y.png}}
	\quad
	\subfigure[Gradient module image $M=\sqrt{f_x^2+f_y^2}$.]{\label{fig:profiles3d-d}\includegraphics[width=0.3\textwidth]{gradient_image.png}}
	\caption{Example computation of the gradient. Original image and gradient image computed using Sobel operators (Operators in Figure \ref{fig:sobel}).}
	\label{fig:profiles3d}
\end{figure}

\begin{figure}[t!]
	\centering
	\subfigure[$th = 0.1*\max(M)$.]{\includegraphics[width=0.3\textwidth]{thresholded_image_1.png}}
	\quad
	\subfigure[$th = 0.2*\max(M)$.]{\includegraphics[width=0.3\textwidth]{thresholded_image_2.png}}
	\quad
	\subfigure[$th = 0.4*\max(M)$.]{\includegraphics[width=0.3\textwidth]{thresholded_image_3.png}}
	\caption{Thresholded images. Different values of the threshold applied to the magnitude of the gradient.}
	\label{fig:thresholding}
\end{figure}


%-------------------------------------------------------------------------------

\subsection{Pseudo-code}

The pseudo-code of the implemented algorithms is shown in Algorithm \ref{algo:fded}.

\clearpage

\begin{algorithm}[t]
\caption{First derivative edge detection algorithms.}
\label{algo:fded}
\begin{algorithmic}[1]
\REQUIRE $im$ input image, threshold $th$.
\STATE Define $operator_x$ and $operator_y$ \COMMENT{Roberts, Prewitt or Sobel.}
\STATE $g_x \leftarrow$ convolution($im$,$operator_x$)
\STATE $g_y \leftarrow$ convolution($im$,$operator_y$)
\STATE $max_M \leftarrow 0$
\FORALL{pixel $i$ in image}
	\STATE $M[i] \leftarrow \sqrt{g_x^2+g_y^2}$ \COMMENT{Gradient magnitude.}
	\IF{$M[i]>max_M$}
		\STATE $max_M \leftarrow M[i]$
	\ENDIF
\ENDFOR
\FORALL{pixel $i$ in image}
	\IF{$M[i] \geq th \times max_M$}
		\STATE $im_{OUT}[i] \leftarrow 255$
	\ELSE
		\STATE $im_{OUT}[i] \leftarrow 0$
	\ENDIF
\ENDFOR
\RETURN output image $\leftarrow im_{OUT}$
\end{algorithmic}
\end{algorithm}

%-------------------------------------------------------------------------------

\section{Algorithms based on second derivative}
\label{sec:second}

The edge detection methods discussed in the previous section are simply based on filtering the 
image with different masks, without taking into account the characteristics of the edges or 
the noise in the image. 

Both algorithms presented in this section (Marr-Hildreth \cite{segm:edge_region:marr:84:digital_step} and Haralick \cite{bb20239}) 
are based on the second derivative of the image, and take steps to reduce noise before 
detecting edges in the image.

%-------------------------------------------------------------------------------

\subsection{The \textit{Marr} and \textit{Hildreth} algorithm}

The Marr-Hildreth algorithm is a method of detecting edges in digital 
images. It is based on finding zero crossing points of the second derivative
of the image. This computation can be done in several ways, but in this work we implement two of these ways  (see block diagram in Figure \ref{fig:blockdiagram2}): convolving the image with a Gaussian kernel and then 
approximating the second derivative (Laplacian) with a 3x3 kernel, or 
convolving the image with a kernel calculated as the Laplacian of a 
Gaussian function. There are more ways to do perform the same tasks, for example, using 
recursive Gaussian filters \cite{Deriche1993Recursively}. 

\begin{figure}[!b]
	\centering
	\includegraphics[width=0.92\textwidth]{blockdiagram2.pdf}
	\caption{Block diagram of Marr-Hildreth algorithm.}
	\label{fig:blockdiagram2}
\end{figure}

The algorithm is divided in two steps, each one described later:
\begin{enumerate}
	\item Grayscale conversion of the input image.
	\item Convolution of the image with:
	\begin{itemize}
		\item a Laplacian of Gaussian (LoG) kernel, (or)
		\item a Gaussian kernel and then a Laplacian operator.
	\end{itemize}
	\item Search of zero crossing points in the filtered image.
\end{enumerate}

IN order to implement this algorithm some auxiliary functions are needed, such as Gaussian kernel and Laplacian of a Gaussian 
kernel generation, and 2-D convolution of an image with a given kernel, 
using different boundary conditions. These operations will be discussed 
in detail in section \ref{sec:appendix1}.

%-------------------------------------------------------------------------------

\subsubsection{Gaussian and LoG kernels}

The main idea of Marr-Hildreth's algorithm is to convolve the input image $f(x,y)$ with a LoG kernel;
\begin{equation}\label{eq:log}
  g(x,y) = [\nabla^2G(x,y)]\star f(x,y), 
\end{equation}
and then finding the zero crossings of $g(x,y)$ to determine the location of edges in $f(x,y)$. 
Because these are linear processes, equation \ref{eq:log} can be written also as
\begin{equation}
  g(x,y) = \nabla^2[G(x,y)\star f(x,y)]
\end{equation}
indicating that the image can be smoothed with a Gaussian filter first, and then compute the Laplacian of the result\footnote{The difference between these approaches lies in the compromise between the accuracy in the calculation and the computational cost (see Section \ref{kernelcomparison}).} .

Then, the algorithm requires the generation of both Gaussian and LoG kernels (see section \ref{sec:appendix1}).\\

The Marr-Hildreth edge-detection algorithm may be summarized as follows:
\begin{enumerate}
	\item Filter the input image with a $n \times n$ Gaussian lowpass filter obtained by sampling the Gaussian kernel (see equation \ref{eq:gaussian_function}). % reescribir (sampleo de un kernel gaussiano)
	\item Compute the Laplacian of the image resulting from step 1, using, for example, the $3\times3$ mask\footnote{Steps 1 and 2 can be merged into one, using a $n\times n$ LoG lowpass filter obtained by sampling equation \ref{eq:log_function}.}:
	\begin{equation*}
		\begin{bmatrix}
			1 &  1 & 1 \\
			1 & -8 & 1 \\
			1 &  1 & 1 \\
		\end{bmatrix}
	\end{equation*}
	\item Find the zero crossings of the image from step 2.
\end{enumerate}

% Sacar la footnote y explicar de otra manera las dos formas de Marr-Hildreth

%-------------------------------------------------------------------------------

\subsubsection{Zero crossing}

% cambiar la primer frase de este parrafo. Explicar de otra forma lo de buscar que haya al menos un cambio de signo en los pixeles vecinos opuestos.

A zero crossing at pixel $p$ implies that the signs of at least two opposite neighboring pixels are 
different. There are four cases to test: left/right, up/down, and the two diagonals. In this case 
two conditions must hold: first, the signs of the opposite pixels must differ, and second, their 
difference in absolute value must be greater than a certain threshold. 

The zero-crossing threshold ($th_{ZC}$) is given as a percentage of the maximum value $max_L$ of the Laplacian 
image (both Gaussian and LoG kernels). Each pixel $p$ has eight neighbors, named according to their position 
as follows.

\begin{center}
\begin{tabular}{ c c c c c }
	$p_{up,left}$		& 					& $p_{up,middle}$	&					& $p_{up,right}$ 		\\
						& $\nwarrow$		& $\uparrow$		& $\nearrow$		&						\\
	$p_{middle,left}$	& $\leftarrow$		& $p$				& $\rightarrow$		& $p_{middle,right}$	\\
						& $\swarrow$		& $\downarrow$		& $\searrow$		&						\\
	$p_{down,left}$		&					& $p_{down,middle}$	&					& $p_{down,right}$.		\\  
\end{tabular}
\end{center}

Then a pixel $p$ is considered as edge pixel if any of the following conditions is true 
(for simplicity the Laplacian image is denoted as $\mathcal{L}$):
\begin{itemize}
	\item $(\mbox{sign}(\mathcal{L}[p_{up,left}])\neq\mbox{sign}(\mathcal{L}[p_{down,right}])$ \& $|\mathcal{L}[p_{up,left}]-\mathcal{L}[p_{down,right}]|>th_{ZC}*max_L$
	\item $(\mbox{sign}(\mathcal{L}[p_{up,middle}])\neq\mbox{sign}(\mathcal{L}[p_{down,middle}])$ \& $|\mathcal{L}[p_{up,middle}]-\mathcal{L}[p_{down,middle}]|>th_{ZC}*max_L$
	\item $(\mbox{sign}(\mathcal{L}[p_{down,left}])\neq\mbox{sign}(\mathcal{L}[p_{up,right}])$ \& $|\mathcal{L}[p_{down,left}]-\mathcal{L}[p_{up,right}]|>th_{ZC}*max_L$
	\item $(\mbox{sign}(\mathcal{L}[p_{middle,left}])\neq\mbox{sign}(\mathcal{L}[p_{middle,right}])$ \& $|\mathcal{L}[p_{middle,left}]-\mathcal{L}[p_{middle,right}]|>th_{ZC}*max_L$. \\
\end{itemize}

Zero crossing detection is the key feature of the Marr-Hildreth edge detection method. The technique 
presented in the previous paragraph is attractive for its simplicity of implementation and its low 
computational cost. In general it yields good results, but for applications that require accurate edge localization, more advanced methods for finding zero crossings with subpixel 
accuracy could be used (e.g.\ marching squares \cite{comp_graph:surf_recon:lorensen:87:marching_cubes}).

%-------------------------------------------------------------------------------

\subsubsection{Pseudo-code}

The pseudo-code of Marr-Hildreth's algorithm is shown in Algorithm \ref{algo:mh}.

\begin{algorithm}[t!]
\caption{Marr-Hildreth edge detection algorithm.}
\label{algo:mh}
\begin{algorithmic}[1]
\REQUIRE $im$ input image, standard deviation $\sigma$, kernel size $n$ and zero-crossing threshold $t_{ZC}$.
\IF{Gaussian kernel}
	\STATE Define Laplacian operator $laplacian$
	\STATE $im_{LAPL} \leftarrow$ convolution($im$,$laplacian$)
\ELSE
	\STATE $kernel \leftarrow$ generate\_kernel($n$,$\sigma$) \COMMENT{Generated Gaussian or LoG kernel}.
	\STATE $im_{SMOOTHED} \leftarrow$ convolution($im$,$kernel$)
	\STATE $im_{LAPL} \leftarrow im_{SMOOTHED}$
\ENDIF
\STATE $max_L \leftarrow 0$
\FORALL{pixel $i$ in image $im_{LAPL}$}
	\IF{$im_{LAPL}[i]>max_L$}
		\STATE $max_L \leftarrow im_{LAPL}[i]$
	\ENDIF
\ENDFOR
\FORALL{pixel $i$ in image $im_{LAPL}$, except borders}
	\FORALL{pair $(p_1,p_2)$ of opposite neighbors of $p$ in $im_{LAPL}$}
		\IF{($\mbox{sign}(im_{LAPL}[p_1])\neq\mbox{sign}(im_{LAPL}[p_2])$) \AND ($|im_{LAPL}[p_1]-im_{LAPL}[p_2]|>th_{ZC}$)}
			\STATE $im_{OUT}[i] \leftarrow 255$
		\ELSE
			\STATE $im_{OUT}[i] \leftarrow 0$
		\ENDIF
	\ENDFOR
\ENDFOR
\RETURN output image $\leftarrow im_{OUT}$
\end{algorithmic}
\end{algorithm}

%-------------------------------------------------------------------------------

\subsection{The \textit{Haralick} algorithm}

In this section we present a detailed description of Haralick's original work \cite{bb20239}.
The main idea of this algorithm is identical to that of the previous method: find zeros in 
the second derivative of the image. In this method, however, the input image is smoothly approximated through local bi-cubic
polynomial fitting. Then, when calculating the second derivative analytically, it is possible to find 
an equivalent expression to find the zeros of the second derivative of the polynomial as a function of 
its parameters.%\footnote{This implementation is slightly different from the traditional implementation 
%of the Haralick algorithm. We do not use the condition concerning the third derivative (to be negative), 
%in order to implement two edge detection methods using only the second derivative (along the 
%Marr-Hildreth algorithm).}

%-------------------------------------------------------------------------------

\subsubsection{Bi-cubic polynomial fitting}
\label{sec:bicubic}

Here, we present the interpolation method used in the original work of Haralick, although there are other options to do this \cite{getreuer}. 

The surrounding neighborhood of a point $(x_0,y_0)$ in the image $f$ is approximated using the following bi-cubic polynomial
\begin{align}
	\label{eq:bicubic:long}
	f(x,y) = k_1 + k_2 (x-x_0) + k_3(y-y_0) + k_4(x-x_0)^2 + k_5(x-x_0)(y-y_0)  +\\
	 k_6(y-y_0) ^2 + k_7(x-x_0)^3 + k_8(x-x_0)^2(y-y_0)  + k_9(x-x_0)(y-y_0) ^2 + k_{10}(y-y_0) ^3 \\
\end{align}
To solve this fitting problem, it is necessary to take more neighbors than coefficients to be adjusted. As there are 10 coefficients to compute, the smallest neighborhood of odd size that accomplishes this has size $5\times5$. Having $10$ coefficients and $25$ data 
points leads to an overdetermined system, which can be solved using least squares or any other suitable fitting technique.\\

In Haralick's work, this polynomial approximation is expressed in a local coordinate system centered on each pixel. In this way, the center of the neighboorhood $(x_0,y_0)$ is always $(0,0)$, and the coordinates $(x, y)$ are offsets from this center point (e.g. in a neighborhood of size $5\times5$, x and y take values between -2 and +2). Thus, the expression of the polynomial is\\

\begin{equation}
	\label{eq:bicubic}
	f(x,y) = k_1 + k_2x + k_3y + k_4x^2 + k_5xy + k_6y^2 + k_7x^3 + k_8x^2y + k_9xy^2 + k_{10}y^3. \\
\end{equation}


Then the solution is computed using least squares, and the local expression of the polynomial ensures that the values of the $k_i$ coefficients are computed in the same way for every pixel in the image. Thus, they can be computed by convolving the image with a set of fixed and precomputed masks, which results in a great speed-up of the algorithm. In the following we will state the approximation problem and show how to derive those masks from its solution.\\

Consider 25 points in a small neighborhood the point $(0,0)$. This gives us an equal number of equations to find 10 coefficients. As mentioned before this leads to an overdetermined system which can be solved by least squares. 
By substituting the 25 data points into the polynomial equation (\ref{eq:bicubic}), the following system of 
equations is obtained,

\begin{equation*}
	\begin{array}{l}
		f_1 = f(x_1,y_1) = k_1 + k_2x_1 + k_3y_1 + k_4x_1^2 + k_5x_1y_1 + k_6y_1^2 + k_7x_1^3 + k_8x_1^2y_1 + k_9x_1y_1^2 + k_{10}y_1^3 \\
		f_2 = f(x_2,y_2) = k_1 + k_2x_2 + k_3y_2 + k_4x_2^2 + k_5x_2y_2 + k_6y_2^2 + k_7x_2^3 + k_8x_2^2y_2 + k_9x_2y_2^2 + k_{10}y_2^3 \\
		\vdots \\
		f_{25} = f(x_{25},y_{25}) = k_1 + k_2x_{25} + k_3y_{25} + k_4x_{25}^2 + k_5x_{25}y_{25} + k_6y_{25}^2 + k_7x_{25}^3 + k_8x_{25}^2y_{25} + k_9x_{25}y_{25}^2 + k_{10}y_{25}^3 . \\
	\end{array}
\end{equation*}

Using matrix notation, the system can be rewritten as

\begin{equation*}
	\begin{bmatrix} 
		f_1		\\ 
		f_2		\\ 
		\vdots	\\
		f_{25}
	\end{bmatrix} 
	= 
	\begin{bmatrix} 
		1 		& x_1 		& y_1 		& x_1^2 	& x_1y_1 		& y_1^2 	& \hdots 	& y_1^3 	\\
		1 		& x_2 		& y_2 		& x_2^2 	& x_2y_2 		& y_2^2 	& \hdots 	& y_2^3 	\\
		\vdots	& \vdots	& \vdots	& \vdots	& \vdots		& \vdots	& \ddots	& \vdots	\\
		1 		& x_{25}	& y_{25}	& x_{25}^2 	& x_{25}y_{25} 	& y_{25}^2 	& \hdots 	& y_{25}^3
	\end{bmatrix}
	\times
	\begin{bmatrix}
		k_1		\\
		k_2		\\
		\vdots	\\
		k_{10}
	\end{bmatrix}
	\Rightarrow \mathbf{f} = \mathbf{A}\mathbf{k} .\\
\end{equation*}

Then, the least squares problem can be solved by using the normal equations,

\begin{equation*}
	(\mathbf{A}^T\mathbf{A})^{-1}\mathbf{A}^T\mathbf{f} = \mathbf{k} 
\end{equation*}

Let us define a matrix $\mathbf{B} \in R^{10\times25}$ such that $\mathbf{B}=(\mathbf{A}^T\mathbf{A})^{-1}\mathbf{A}^T$, thus

$$ \mathbf{k} = \mathbf{B}\mathbf{f} $$

\begin{equation*}
	\begin{bmatrix}
		b_{1,1}		& b_{1,2}	& \hdots	& b_{1,25}	\\
		b_{2,1}		& b_{2,2}	& \hdots	& b_{2,25}	\\
		\vdots		& \vdots	& \ddots	& \vdots	\\
		b_{10,1}	& b_{10,2}	& \hdots	& b_{10,25}
	\end{bmatrix}
	\times
	\begin{bmatrix}
		f_1		\\
		f_2		\\
		\vdots	\\
		f_{25}
	\end{bmatrix}
	=
	\begin{bmatrix}
		k_1		\\
		k_2		\\
		\vdots	\\
		k_{10}
	\end{bmatrix} .\\
\end{equation*}

For each coefficient ($i$ from $1$ to $10$), 

\begin{equation}
	\label{eq:coefficients}
	k_i = b_{i,1}f_1 + b_{i,2}f_2 + b_{i,3}f_3 + \hdots + b_{i,25}f_{25} \ \ \Rightarrow \ \ \mathbf{k_i} = \mathbf{b_i}\mathbf{f} ,\\
\end{equation}

where $\mathbf{b_i}$ is the vector containing the $i-th$ row of $B$, i.e.

\begin{equation}
	\label{eq:b_i_v}
	\mathbf{b_i} = \begin{bmatrix}	b_{i,1}		& b_{i,2}	& \hdots	& b_{i,25}
					\end{bmatrix}.\\
\end{equation}

Let us rearrange $\mathbf{b_i}$ as a $5\times5$ matrix and denote it by $\mathbf{mask_i}$ as follows
\begin{equation}
	\label{eq:b_i}
	\mathbf{mask_i} = \begin{bmatrix}	b_{i,1}		& b_{i,2}	& \hdots	& b_{i,5}	\\
									b_{i,6}		& b_{i,7}	& \hdots	& b_{i,10}	\\
									\vdots		& \vdots	& \ddots	& \vdots	\\
									b_{i,21}	 & b_{i,22}	& \hdots	& b_{i,25}	\\
					\end{bmatrix}.\\
\end{equation}

\vspace{1ex}
We will compute one value of $k_i$ for each pixel on the image. Thus we can store these coefficients in a matrix $\bf{K_i}$ of the same size as the original image. Then, using the mask shown in Equation \ref{eq:b_i} we can obtain $\bf{K_i}$ as the convolution of the original image with $\mathbf{mask_i}$. \\
\begin{equation}
	\label{eq:convolution_b}
	\mathbf{K_i} = f \star \mathbf{mask_i} \: \mathtt{for} \: i \in \{1 \ldots 10\}\\
\end{equation}

As we expressed the approximation in a local coordinate system, the coefficients $b_{i,j}$ will be the same for every pixel, thus, this convolution is performed against a fixed and precomputed mask $\mathbf{mask_i}$. The numeric values of these 5x5 masks used in our experiments are shown in Table \ref{table:b_i}.



%-------------------------------------------------------------------------------

\subsubsection{Analytical calculation of the second derivative}
\label{sec:secderivative}

The main idea of Haralick's algorithm, as stated in the original work, is to find "negative sloped zero crossings of the second derivative". This means that it is actually looking for ascending step edges. According to Haralick's definition, a pixel will lie on such an edge if the following three conditions hold\footnote{Please note that there is a typo in Haralick's original paper. The statement of the idea is presented at the beggining of Section III, in the first column of page 42. The three conditions are presented at the end of the same section, in the second column. There it reads $f''_{\alpha}(\rho)<0$, $f''_{\alpha}(\rho)=0$ and $f'_{\alpha}(\rho)\neq 0$. Clearly, the first and second conditions can't be true at the same time, thus the first one should be $f'''_{\alpha}(\rho)<0$.}:

\begin{enumerate}
\item the first derivative is non zero.
\item the second derivative is zero.
\item the third derivative is negative.
\end{enumerate}

After the neighborhood of each point of the image is approximated using the bi-cubic polynomial expression in equation \ref{eq:bicubic}, the idea is to compute the derivatives of the image in the direction of the gradient using that approximation.\\

Let $\theta$ be the gradient angle, defined clockwise with respect to the y-axis\footnote{Although it seems a non standard choice, we followed exactly from the original work}. We approximate it using the first order terms of the polynomial \ref{eq:bicubic} obtaining the following expression:

\begin{align}
\label{eq:sincos}
	\sin(\theta) & = -\frac{k_2}{\sqrt{k_2^2 + k_3^2}} \nonumber \\
	\cos(\theta) & = -\frac{k_3}{\sqrt{k_2^2 + k_3^2}}. \\
\end{align}

Let us consider the line $r$ passing by $(0,0)$ with angle $\theta$. The coordinates of each point $(x,y)$ on this line can be described in terms of  the angle $\theta$ and the distance $\rho$ to $(0,0)$ as follows

\begin{align*}
	x = \rho\sin{\theta} \\
	y = \rho\cos{\theta} 
\end{align*}

If we substitute the above expressions in the bi-cubic polynomial of Eq. \ref{eq:bicubic}, we obtain

\begin{equation}
	f_{\theta}(\rho) = C_0 + C_1\rho + C_2\rho^2 + C_3\rho^3 ,
\end{equation}

where

\begin{align}
\label{eq:c}
	C_0 & = k_1 \nonumber \nonumber \\
	C_1 & = k_2\sin(\theta) + k_3\cos(\theta) \nonumber \\
	C_2 & = k_4\sin^2(\theta) + k_5\sin(\theta)\cos(\theta) + k_6\cos^2(\theta) \nonumber \\
	C_3 & = k_7\sin^3(\theta) + k_8\sin^2(\theta)\cos(\theta) + k_9\sin(\theta)\cos^2(\theta) + k_{10}\cos^3(\theta). \nonumber \\
\end{align}

The derivatives are obtained as follows.

\begin{align}
	f'_{\theta}(\rho) = C_1 + 2C_2\rho + 3C_3\rho^2 \nonumber \\
	f''_{\theta}(\rho) = 2C_2 + 6C_3\rho \nonumber \\
	f'''_{\theta}(\rho) = 6C_3 .\nonumber \\
\end{align}

The simplest way to impose the above-mentioned conditions is starting with the third one, i.e. that the third derivative has to be negative. Thus,

\begin{equation}
	f'''_{\theta}(\rho) = 6C_3 < 0 \ \ \Rightarrow \ \ C_3 < 0.
\end{equation}

By construction $\theta$ is the direction of the gradient, which means that the edge will always be an ascending step. Thus by definition the function $f_{\theta}(\rho)$ is non-decreasing in a neighborhood of $\rho=0$, which means that $f'_{\theta}(0) \geq 0$. This in turn implies that $C_1 \geq 0$.

The second condition that the second derivative is equal to zero becomes

\begin{equation}\label{eq:haralick:cond_b_orig}
	f''_{\theta}(\rho) = 2C_2 + 6C_3\rho = 0
\end{equation}

Ideally, if the edge point falls exactly on a grid location, the polynomial function 
should be zero at $\rho=0$. But due to the finite nature of the image grid, the edge could be located at non integer locations. Thus, the condition is relaxed asking that the polynomial becomes zero in a neighborhood of radius $\rho_0>0$ centered at $\rho=0$. 
With this relaxation, the condition \ref{eq:haralick:cond_b_orig} becomes

\begin{equation}
\exists\rho \in (-\rho_0,\rho_0) \:\:  \mathtt{such\:that}  \:\:  2C_2 + 6C_3\rho = 0 \\
\end{equation}

Thus, the solution is $\rho_*=-\frac{C_2}{3C_3} $ and imposing $|\rho_*|<\rho_0$ we obtain the second condition

\begin{equation}
\left| \frac{C_2}{3C_3} \right| < \rho_0,
\end{equation}

Finally,  the first condition is that the first derivative is non zero, 

\begin{equation}\label{eq:cond:first}
f'_{\theta}(\rho) = C_1 + 2C_2\rho + 3C_3\rho^2 \neq 0 \\
\end{equation}

If we evaluate $f'_{\theta}$ on the solution $\rho_*$ using the above formula, we obtain

\begin{equation}\label{eq:cond:first:optim}
f'_{\theta}(\rho_*) = C_1 - \frac{C_2^2}{3C_3}  \\
\end{equation}

as $C_1>=0$ and $C_3<0$, $f'_{\theta}(\rho_*)$ will always be positive, thus the first condition always hold by construction and does not need to be verified.\\

In Haralick's work $\rho_0$ is a fixed threshold which acts as a parameter of the algorithm.
Its value must be greater than zero and and less than the size of the grid (i.e. $\rho_0<1$). In this work we obtained the best results with values between $0.4$ and $0.6$.\\

%-------------------------------------------------------------------------------

\subsubsection{Algorithm}

The Haralick edge detection algorithm is summarized in the following 4 steps:

\begin{enumerate}
	\item For each pixel in the image, find the coefficients $k_1 \hdots k_{10}$, as shown in section \ref{sec:bicubic}.
	\item Compute $\sin(\theta)$ and $\cos(\theta)$ (equations \ref{eq:sincos}).
	\item Compute $C_2$ and $C_3$ (equations \ref{eq:c}).
	\item If $\left| \frac{C_2}{3C_3} \right| < \rho_0$ and $C_3 < 0$, then the candidate is an edge point.
\end{enumerate}

%-------------------------------------------------------------------------------

\subsubsection{Pseudo-code}

The pseudo-code of Haralick's algorithm is shown in Algorithm \ref{algo:haralick}.

\begin{algorithm}[t]
\caption{Haralick edge detection algorithm.}
\label{algo:haralick}
\begin{algorithmic}[1]
\REQUIRE $im$ input image (width $w$, height $h$), edge point condition threshold $\rho_0$.
\STATE Define the ten $5\times5$ masks ($mask_1\dots mask_{10}$) used to determine coefficients $k_1$ to $k_{10}$ \COMMENT{See Table \ref{table:b_i}.}
\FORALL{pixel $i$ in image $im$}
	\STATE $neighbors \leftarrow$ $5\times5$ neighborhood of pixel $i$ in image $im$
	\FOR{$j=1$ \TO $10$}
		\STATE $k_j \leftarrow$ convolution($neighbors$,$mask[j]$)
	\ENDFOR
	\STATE $C_2 \leftarrow \frac{k_2^2k_4 + k_2k_3k_5 + k_3^2k_6}{k_2^2 + k_3^2}$
	\STATE $C_3 \leftarrow \frac{k_2^3k_7 + k_2^2k_3k_8 + k_2k_3^2k_9 + k_3^3k_{10}}{(\sqrt{k_2^2 + k_3^2})^3}$
	\IF{{$|C_2/3C_3|\leq\rho_0$} \AND {$C_3<0$}}
		\STATE $im_{OUT}[i] \leftarrow 255$
	\ELSE
		\STATE $im_{OUT}[i] \leftarrow 0$
	\ENDIF
\ENDFOR
\RETURN output image $\leftarrow im_{OUT}$
\end{algorithmic}
\end{algorithm}

%-------------------------------------------------------------------------------

\section{Common Mathematical Operations}
\label{sec:appendix1}

All implemented algorithms use some common mathematical operations that are independent of the algorithms themselves. 
These operations, although basic, have a great impact on the algorithm outcome, and thus they need to be 
implemented with care. In this section those operations are reviewed.

%-------------------------------------------------------------------------------

%\subsection{Grayscale conversion}
%\label{sec:grayscale}

%The first step in every algorithm presented above is to convert color images to gray intensity images. 
%For this purpose, \href{http://www.libpng.org/}{libpng} coefficients are used,
%\begin{equation}
%    Y = (6968 R + 23434 G + 2366 B) / 32768
%\end{equation}
%where $R$, $G$ and $B$ are the red, green and blue components respectively\footnote{Must be carefully implemented, using \texttt{float} to avoid truncated results. See code in section \ref{app:marr-hildreth}.}.

%-------------------------------------------------------------------------------

\subsection{Kernel generation}

Some of the algorithms presented above require the use of a Gaussian kernel or a LoG kernel. These 
kernels are generated by sampling the corresponding analytical function, which in each case depends 
on the standard deviation $\sigma$ of the Gaussian function. The result is an array of 
size $n$ by $n$.

% Explicar que voy a crear un patch centrado en [x,y]=[0,0], y un poco mas de la generacion del patch.
% Explicar que se samplea en el centro de los pixeles (hay varias formas de generar el patch, por ejemplo,
% que cada valor sea la media de la guncion en el pixel, etc).

%-------------------------------------------------------------------------------

\subsubsection{Gaussian kernel}

The Gaussian convolution mask is generated by sampling the 2-D Gaussian function (centered at $(0,0)$)
%\footnote{Note that for simplicity the normalizing coefficient $1/\sqrt{2\pi\sigma^2}$ is omitted.}
\begin{equation}
	\label{eq:gaussian_function}
	G(x,y) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{x^2+y^2}{2\sigma^2}}
\end{equation}
where $\sigma$ is the standard deviation (sometimes $\sigma$ is called the \textit{scale space constant}).

The size of the kernel $n$ and the standard deviation of the exponential function $\sigma$ are both 
input parameters, but these are not strictly independent of each other. 
The value of $n$ needs to be large enough to ensure that no information is lost when creating the kernel $G$. To ensure this, $n$ is taken equal to the first odd integer greater than $6\sigma$. Larger values of $n$ do not add more significant samples ââof $G$, and increase the number of operations in the convolution.

Figure \ref{fig:gaussian_kernel} shows a Gaussian kernel, generated with $\sigma = 4$ and $n = 25$ 
(first odd integer greater than $6\sigma=24$).
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\textwidth]{kernel_gaussian.pdf}
	\caption{Gaussian kernel, $\sigma=4$, $n=25$. It is easy to see that the selected value of $n$ is 
large enough to have a good approximation of the Gaussian function in the kernel.}
	\label{fig:gaussian_kernel}
\end{figure}

%-------------------------------------------------------------------------------

\subsubsection{LoG kernel}

The Laplacian of Gaussian $\nabla^2G(x,y)$ can be obtained analyically first and then a discrete mask 
can be computed by sampling the analytical kernel. Using this kernel for edge detection involves only 
one convolution with the input image (unlike the Gaussian kernel case, in which two convolutions 
have to be performed, one with the kernel and another with the Laplacian operator), but the kernel 
support must be greater in order to obtain the same precision.

% Una linea explicando que para la misma presicion se requiere un soporte mas grande (y linkar a la seccion siguiente).

\begin{equation}
	LoG \stackrel{\triangle}{=}\nabla^2G(x,y)=\frac{\partial^2}{\partial^2 x}G(x,y) + \frac{\partial^2}{\partial^2 y}G(x,y)
\end{equation}

We first compute

\begin{equation} 
	\frac{\partial}{\partial x}G(x,y)=-\frac{1}{\sqrt{2\pi\sigma^2}}\frac{x}{\sigma^2}e^{-(x^2+y^2)/2\sigma^2},
\end{equation}
\begin{equation} 
	\frac{\partial}{\partial y}G(x,y)=-\frac{1}{\sqrt{2\pi\sigma^2}}\frac{y}{\sigma^2}e^{-(x^2+y^2)/2\sigma^2},
\end{equation}
\begin{equation} 
	\frac{\partial^2}{\partial^2 x}G(x,y)=\frac{1}{\sqrt{2\pi\sigma^2}}\frac{x^2-\sigma^2}{\sigma^4}e^{-(x^2+y^2)/2\sigma^2},
\end{equation}
\begin{equation} 
	\frac{\partial^2}{\partial^2 y}G(x,y)=\frac{1}{\sqrt{2\pi\sigma^2}}\frac{y^2-\sigma^2}{\sigma^4}e^{-(x^2+y^2)/2\sigma^2}.
\end{equation}
Therefore we obtain
\begin{equation}
	\label{eq:log_function}
	LoG(x,y)=\frac{1}{\sqrt{2\pi\sigma^2}}\frac{x^2+y^2-2\sigma^2}{\sigma^4}e^{-(x^2+y^2)/2\sigma^2}.
\end{equation}\\

Now the LoG kernel is generated by sampling the function defined in equation \ref{eq:log_function}. 
Figure \ref{fig:log_kernel} shows a LoG kernel, generated using the values $\sigma=4$ and $n=31$.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\textwidth]{kernel_log.pdf}
	\caption{Laplacian of a Gaussian kernel, $\sigma=4$, $n=31$. The selected value of $n$ is sufficient 
to have a good approximation of the LoG function in the kernel, but it is greater than in the case of 
Gaussian kernel.}
	\label{fig:log_kernel}
\end{figure}

%-------------------------------------------------------------------------------

\subsubsection{Gaussian and LoG functions comparison}
\label{kernelcomparison}

As mentioned before, the size $n$ of the kernel and the standard deviation $\sigma$ of the exponential function 
are not independent. For the same $\sigma$ value , the function LoG has wider support than the
Gaussian function (i.e. LoG function has a slower decay), so a greater value of $n$ is needed to correcly sample the LoG kernel.\\

Figure \ref{fig:kernels} shows both functions generated with the same value of $\sigma$. It is clear that we must use a larger kernel size in the LoG function case (approximately 18\% larger). For 
example, using $\sigma=4$, the optimum value for $n$ in the case of the Gaussian function is the 
first odd integer greater than $6\sigma$, which is $25$, and for the case of LoG function, would 
be $29$.
% Especificar cual es el criterio para el tamaÃ±o del LoG.
% mirar en el software si no es mejor quitar la dependencia con n, y que se decida internamente el tamaÃ±o
% del kernel en funcion de sigma.

\begin{figure}[ht]
	\centering
	\includegraphics[width=1.0\textwidth]{kernels.pdf}
	\caption{Comparison of the Gaussian and LoG functions.}
	\label{fig:kernels}
\end{figure}

%-------------------------------------------------------------------------------

\subsection{Convolution}

When performing a convolution, it is necessary to define the boundary conditions used to compute it near the edges of the image, and to get a valid output of the same size as input image. In this paper, 
two methods were implemented: zero-padding and boundary reflection. Zero-padding completes the borders of the image with zero valued pixels. Reflection completes those pixels with the corresponding symmetric pixel value  relative to the edge of the image. Direct convolution is not the only way of filtering an image with a kernel, there are other methods such as FFT convolution or recursive filtering.%\footnote{Implementations of these methods can be found in the \href{https://tools.ipol.im/wiki/author/code/hatchery/}{IPOL Code Hatchery}.}.

%-------------------------------------------------------------------------------


%-------------------------------------------------------------------------------

\section{Results}
\label{sec:results}

The results of each algorithm are first shown for a simple image composed of a white square on a black background, see Figure \ref{fig:original1}. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.2\textwidth]{results/square127.png}
	\caption{Test image 1: white square on black background (127$\times$127 pixels).}
	\label{fig:original1}
\end{figure}

Figures \ref{fig:result1-a} to \ref{fig:result1-f} show the output of each algorithm (including execution times\footnote{Running on Intel Core i3 CPU (2.53GHz), 3 Gb RAM, standard laptop. Note that the execution time of the algorithms Roberts, Prewitt and Sobel are the same, because they run simultaneously.}). 

\begin{figure}[h!]
	\centering
	\subfigure[Roberts. $th=0.1$. $\text{Exec-time}:0.02s$.]{\label{fig:result1-a}\includegraphics[width=0.2\textwidth]{results/square127_roberts.png}}
	\quad
	\subfigure[Prewitt. $th=0.1$. $\text{Exec-time}:0.02s$.]{\label{fig:result1-b}\includegraphics[width=0.2\textwidth]{results/square127_prewitt.png}}
	\quad
	\subfigure[Sobel. $th=0.1$. $\text{Exec-time}:0.02s$.]{\label{fig:result1-c}\includegraphics[width=0.2\textwidth]{results/square127_sobel.png}}

	\subfigure[Marr-Hildreth (Gaussian). $\sigma=1.5$, $n=13$, $th_{ZC}=0.1$. $\text{Exec-time}:0.03s$.]{\label{fig:result1-d}\includegraphics[width=0.2\textwidth]{results/square127_marr-hildreth.png}}
	\quad
	\subfigure[Marr-Hildreth (LoG). $\sigma=1.5$, $n=17$, $th_{ZC}=0.1$. $\text{Exec-time}:0.05s$.]{\label{fig:result1-e}\includegraphics[width=0.2\textwidth]{results/square127_marr-hildreth-log.png}}
	\quad
	\subfigure[Haralick. $\rho=0.4$. $\text{Exec-time}:0.04s$.]{\label{fig:result1-f}\includegraphics[width=0.2\textwidth]{results/square127_haralick.png}}
	\caption{Results of the algorithms using the Figure \ref{fig:original1} as input image. The first three (\subref{fig:result1-a}, \subref{fig:result1-b} and \subref{fig:result1-c}) correspond to the first derivative methods (Roberts, Prewitt and Sobel), then the following two (\subref{fig:result1-d} and \subref{fig:result1-e}) are from the Marr-Hildreth algorithm using Gaussian and LoG kernels, and the last one (\subref{fig:result1-f}) corresponds to the Haralick algorithm. Note the rounded corners on the Marr-Hildreth results, due to Gaussian blur.}
	\label{fig:result1}
\end{figure}

In this simple case, the first derivative edge detection algorithms run better and faster. All algorithms show consistent results. Thicker edges appear in the results of Haralick, due to smooth image model that is imposed in this algorithm. 

\begin{figure}[t!]
	\centering
	\includegraphics[width=0.48\textwidth]{results/molino_bw.png}
	\caption{Test image 2: Windmill (1000$\times$563 pixels).}
	\label{fig:original2}
\end{figure}

Now the performance of each algorithm is analyzed using a natural image (\textit{Windmill}) shown in Figure \ref{fig:original2}. 
The results of the first derivative edge detection algorithms are shown Figures \ref{fig:result3-b} to \ref{fig:result3-d}. Figures \ref{fig:result3-e} and \ref{fig:result3-f} show the results obtained using the Marr-Hildreth algorithm (both Gaussian and LoG kernels), and Figure \ref{fig:result3-g} shows the results obtained using the Haralick algorithm. Table \ref{exectime2} summarizes the execution times for each of the algorithms. 


\begin{table}[t!]
	\begin{center}
	\begin{tabular}{| l | r |}
		\hline \rule{0pt}{3ex}
		\cellcolor[gray]{0.8} \textbf{Algorithm}	& \cellcolor[gray]{0.8} \textbf{Execution time (s)}	\\ \hline \rule{0pt}{3ex}
		Roberts, Prewitt and Sobel					& $0.550 \ s$										\\ \hline \rule{0pt}{3ex}
		Marr-Hildreth (Gaussian)					& $1.050 \ s$										\\ \hline \rule{0pt}{3ex}
		Marr-Hildreth (LoG)							& $1.440 \ s$										\\ \hline \rule{0pt}{3ex}
		Haralick									& $0.930 \ s$										\\
		\hline
	\end{tabular}
	\end{center}
	\caption{Execution time of the algorithms (including I/O) using the \emph{Windmill} image from Figure \ref{fig:original2} as input image (1000$\times$563 pixels, 3 channels).}
	\label{exectime2}
\end{table}

In this example the difference in performance between the first derivative and the second derivative algorithms is more meaningful.  For each image in Figure \ref{fig:result3}, we show an area of ââinterest, enlarging it to have a better view of the details. Note that none of the first derivative methods (even with a loose threshold) detect the lower edge of the blade (which is shaded). Neither the Haralick algorithm is able to detect it. However, the Marr-Hildreth algorithm detects it, using either a Gaussian or a LoG kernel. 

Another observation is that edges detected by Haralick's algorithm appear to be thicker than those detected with other ones. This may be due the regularity that Haralick assumes. 

\begin{figure}[h!]
	\centering
	\subfigure[Original.]{\label{fig:result3-a}\includegraphics[width=0.48\textwidth]{results/molino_bw_zoom.png}}	
	
	\subfigure[Roberts. $th=0.1$. $\text{Exec-time}:0.55s$.]{\label{fig:result3-b}\includegraphics[width=0.48\textwidth]{results/molino_roberts_zoom.png}}
	\quad
	\subfigure[Prewitt. $th=0.1$. $\text{Exec-time}:0.55s$.]{\label{fig:result3-c}\includegraphics[width=0.48\textwidth]{results/molino_prewitt_zoom.png}}
	
	\subfigure[Sobel. $th=0.1$. $\text{Exec-time}:0.55s$.]{\label{fig:result3-d}\includegraphics[width=0.48\textwidth]{results/molino_sobel_zoom.png}}
	\quad
	\subfigure[Marr-Hildreth (Gaussian). $\sigma=3$, $n=25$, $th_{ZC}=0.07$. $\text{Exec-time}:1.05s$.]{\label{fig:result3-e}\includegraphics[width=0.48\textwidth]{results/molino_marr-hildreth_zoom.png}}

	\subfigure[Marr-Hildreth (LoG). $\sigma=3$, $n=29$, $th_{ZC}=0.13$. $\text{Exec-time}:1.44s$.]{\label{fig:result3-f}\includegraphics[width=0.48\textwidth]{results/molino_marr-hildreth-log_zoom.png}}
	\quad
	\subfigure[Haralick. $\rho=0.4$. $\text{Exec-time}:0.93s$.]{\label{fig:result3-g}\includegraphics[width=0.48\textwidth]{results/molino_haralick_zoom.png}}
	
	\caption{Results of the first derivative, Marr-Hildreth and Haralick's algorithms on the \textit{Windmill} image.}
	\label{fig:result3}
\end{figure}

\clearpage

%-------------------------------------------------------------------------------

\subsection{Further examples}
\label{sec:examples}

Further examples obtained with the implemented algorithms are shown in Figures \ref{fig:example1} and \ref{fig:example2}. More examples can be found in the online \href{\demourl}{demo}.

\begin{figure}[h!]
	\centering
	\subfigure[Original.]{\includegraphics[width=0.3\textwidth]{examples/lena_bw.png}}

	\subfigure[Roberts. $th=0.1$.]{\includegraphics[width=0.3\textwidth]{examples/lena_roberts.png}}
	\quad
	\subfigure[Prewitt. $th=0.1$.]{\includegraphics[width=0.3\textwidth]{examples/lena_prewitt.png}}
	\quad
	\subfigure[Sobel. $th=0.1$.]{\includegraphics[width=0.3\textwidth]{examples/lena_sobel.png}}

	\subfigure[Marr-Hildreth (Gaussian). $\sigma=2$, $n=21$, $th_{ZC}=0.15$.]{\includegraphics[width=0.3\textwidth]{examples/lena_marr-hildreth.png}}
	\quad
	\subfigure[Marr-Hildreth (LoG). $\sigma=2$, $n=25$, $th_{ZC}=0.15$.]{\includegraphics[width=0.3\textwidth]{examples/lena_marr-hildreth-log.png}}
	\quad
	\subfigure[Haralick. $\rho=0.35$.]{\includegraphics[width=0.3\textwidth]{examples/lena_haralick.png}}
	\caption{Example: Lena (512$\times$512 pixels).}
	\label{fig:example1}
\end{figure}

\clearpage

Some observations: 
\begin{itemize}
	\item The first derivative algorithms, although they work properly and run fast, have some problems like discontinuity of the edges. They are also very sensitive to noise, which make them detect spurious edges (More sophisticated methods help to improve this, e.g. Canny edge detector \cite{Canny1986}). \\
	\item The Marr-Hildreth algorithm (in its two versions) achieved interesting results regarding edge details. This algorithm provides a first attempt to obtain regular edges, because of the filtering with a Gaussian kernel. This behavior can be seen in Lena's hair (Figure \ref{fig:example1}), or inside the oranges (example \ref{fig:example2}). \\
	\item As mentioned earlier, Haralick's algorithm is the first to assume greater regularity of the image in the neighborhood of a pixel (third order). This causes thicker edges, as shown in both examples. But, note that some edges are only detected with this algorithm, e.g. the lower edges of the oranges, which are in the shadow, in Figure \ref{fig:example2}. These edges are quite smooth, so that the Haralick model is well suited to them, and they do not represent an abrupt change in the intensity to be detected by other methods. \\
\end{itemize}

\newcommand{\factuno}{0.31}
\begin{figure}[t!]
	\centering
	\subfigure[Original.]{\includegraphics[width=0.3\textwidth]{examples/oranges_bw.png}}

	\subfigure[Roberts. $th=0.1$]{\includegraphics[width=\factuno\textwidth]{examples/oranges_roberts.png}}
	\quad
	\subfigure[Prewitt. $th=0.1$]{\includegraphics[width=\factuno\textwidth]{examples/oranges_prewitt.png}}
	\quad
	\subfigure[Sobel. $th=0.1$]{\includegraphics[width=\factuno\textwidth]{examples/oranges_sobel.png}}

	\subfigure[Marr-Hildreth (Gaussian). $\sigma=2$, $n=21$, $th_{ZC}=0.15$.]{\includegraphics[width=\factuno\textwidth]{results/orange_mhg_s_2_n_21_th_0.15.png}}
	\quad
	\subfigure[Marr-Hildreth (LoG). $\sigma=2$, $n=25$, $th_{ZC}=0.15$.]{\includegraphics[width=0.3\textwidth]{results/orange_mhl_s_2_n_25_th_0.15.png}}
	\quad
	\subfigure[Haralick. $\rho=0.4$.]{\includegraphics[width=\factuno\textwidth]{examples/oranges_haralick.png}}
	\caption{Example: Oranges (536$\times$480 pixels).}
	\label{fig:example2}
\end{figure}

\subsection{Effect of the scale parameter}
In this section we will discuss the effect of the parameters for each of the reviewed algorithms. As a general rule, they all take one threshold parameter which acts as a scale parameter. As Figure \ref{fig:results:parameters:roberts:parameter} shows for the \emph{Roberts} algorithm, the bigger that threshold is, the coarser is the edge map obtained.

In Figure \ref{fig:results:parameters:roberts:saliency} we show a summary of the threshold's behavior for this algorithm, in the whole range of possible values $[0,1]$. For each image, this information is summarized in a saliency map which serves to assess the quality of the obtained hierarchical set of edges.
The saliency map is constructed by sampling the scale range (using steps of $0.05$) and computing the edge map corresponding for each scale. Then each edge is labeled with its scale of disappearance $\alpha^-$, which is the maximum scale at which an edge is present in the output edge map. This scale is drawn with a \emph{hot} colormap (black, red, yellow, white). Intuitively, this means that 'hotter' edges last longer across scales and thus are more meaningful.
These results show two important properties. First, the obtained stack of edges are causal, i.e. as the scale parameter increases the edge map gets coarser. This can be verified by observing the values of $\alpha^-$ assigned to each contour.
If a contour has a high $\alpha^-$ value it means that it will survive for a long time in the detection process. On the other hand, small values mean that it will be removed at early stages.
As the figure shows, the highest values of $\alpha^-$ are assigned to the most coarser segmentation.
And second, the stack of edges is geometrically accurate, i.e. the borders present in each scale are a strict subset of the previous (finer) scale. If they were not included they will be seen as new contours in the saliency map.
These results show empirical evidence that the obtained hierarchy holds the strong causality property introduced by Morel and Solimini in \cite{book:morel:95:variational_pde}.

In Figures \ref{fig:results:parameters:first:saliency:a} and \ref{fig:results:parameters:first:saliency:b} we compare the three first derivative algorithms by means of their saliency maps. As the results show, they all present a similiar behavior, however the are small differences in the results of Roberts vs the other two algorithms. For example in the latter, edges surrounding the segments of the orange are better defined, because they have more relative weight than other spurious borders. This is explained by the smoothing introduced by Prewitt and Sobel masks explained in Sections \ref{sec:first:sobel} and \ref{sec:first:sobel}, which removes theses spurious edges and thus improves the meaningfulness of the stable ones.

In Figures \ref{fig:results:parameters:second:saliency:a} and \ref{fig:results:parameters:second:saliency:b} we compare the second derivative algorithms by means of their saliency maps. In the first place, we obtain very similar hierarchies for both Marr-Hildreth implementations, which validates the affirmation that the difference is merely about computational effort if both are correctly implemented. However, the LoG implementation seems to give slightly better results, this is probably because it provides a more accurate discretization of the differential operators than the Gaussian approach. See for instance the clothing sticks in Figure \ref{fig:results:parameters:second:saliency:b}, where the boundaries in the LoG case seem better defined.


\renewcommand{\anchocinco}{2.5cm}
\newcommand{\anchocuatro}{4.5cm}

\begin{figure*}[ht]
  \centering
\figRowMultiscaleHHH{test}{roberts}{0002}
\figRowMultiscaleHHH{test}{roberts}{0003}
\figRowMultiscaleHHH{test}{roberts}{0004}
  \caption{Results of the \textit{Roberts} algorithm on our sample images. For each example we show the original image on the left and the results corresponding to parameter values of 0.1, 0.2 and 0.3 respectively.}
  \label{fig:results:parameters:roberts:parameter}
%\vskip \espaciotabla
\end{figure*}

\renewcommand{\anchocuatro}{8cm}
\begin{figure*}[ht]
  \centering
\figRowMultiscaleH{test}{roberts}{0002}
\figRowMultiscaleH{test}{roberts}{0003}
\figRowMultiscaleH{test}{roberts}{0004}
  \caption{Results of the \textit{Roberts} algorithm on our sample images. For each example we show the original image on the left and a saliency map on the right. The value of each contour corresponds to the scale of disappearance  $\alpha^-$ of each region. }
  \label{fig:results:parameters:roberts:saliency}
%\vskip \espaciotabla
\end{figure*}

\renewcommand{\anchocuatro}{4.5cm}

\begin{figure*}[ht]
  \centering
\figRowMultiscaleHH{test}{0002}
\figRowMultiscaleHH{test}{0003}
\figRowMultiscaleHH{test}{0004}
\figRowMultiscaleHH{test}{0005}
  \caption{Results of the first derivative algorithms on our sample images. For each example we show the original image on the left and the saliency map of each algorithm (Roberts, Sobel, Prewitt) respectively.
  The value of each contour corresponds to the scale of disappearance  $\alpha^-$ of each region.}
  \label{fig:results:parameters:first:saliency:a}
%\vskip \espaciotabla
\end{figure*}

\begin{figure*}[ht]
  \centering
\figRowMultiscaleHH{test}{0006}
\figRowMultiscaleHH{test}{0007}
\figRowMultiscaleHH{test}{0008}
  \caption{Results of the first derivative algorithms on our sample images. For each example we show the original image on the left and a saliency map of each algorithm (Roberts, Sobel, Prewitt) respectively.
  The value of each contour corresponds to the scale of disappearance  $\alpha^-$ of each region.}
  \label{fig:results:parameters:first:saliency:b}
%\vskip \espaciotabla
\end{figure*}

\begin{figure*}[ht]
  \centering
\figRowMultiscaleHHHH{test}{0002}
\figRowMultiscaleHHHH{test}{0003}
\figRowMultiscaleHHHH{test}{0004}
\figRowMultiscaleHHHH{test}{0005}
  \caption{Results of the second derivative algorithms on our sample images. For each example we show the original image on the left and a saliency map of each algorithm (Marr-Hildreth-Gaussian, Marr-Hildreth-Log, Haralick) respectively.
  The value of each contour corresponds to the scale of disappearance  $\alpha^-$ of each region.}
  \label{fig:results:parameters:second:saliency:a}
%\vskip \espaciotabla
\end{figure*}

\begin{figure*}[ht]
  \centering
\figRowMultiscaleHHHH{test}{0006}
\figRowMultiscaleHHHH{test}{0007}
\figRowMultiscaleHHHH{test}{0008}
  \caption{Results of the second derivative algorithms on our sample images. For each example we show the original image on the left and the saliency map of each algorithm (Marr-Hildreth-Gaussian, Marr-Hildreth-Log, Haralick) respectively.
  The value of each contour corresponds to the scale of disappearance  $\alpha^-$ of each region.}
  \label{fig:results:parameters:second:saliency:b}
%\vskip \espaciotabla
\end{figure*}

\subsection{Effect of the smoothing parameter}
As we stated in previous section, all the reviewed algorithms share a scale parameter (threshold), however, the Marr-Hildreth Algorithm also has a smoothing step which adds an additional parameter $\sigma$, which controls the amount of regularization. In Figure \ref{fig:results:parameters:marr:sigma} we show the results using different  $\sigma$ values. As sigma increases more spurious edges are removed and the boundaries of the objects look smoother. However, if we keep increasing it we start removing meaningful edges (see the cloth band on the hat of Lena).

\subsection{Discussion}
In this section we will discuss the obtained results and contrast them with the claims made by the original authors.
In the case of the first derivative algorithms, they are very simple and the claims made by the original authors are straight forward to verify. The Roberts algorithm was presented in his Phd Thesis (\cite{im_proc:segmentation:roberts:1963:boundary_extraction}, Chapter IV ) as a step of a more complex 3D reconstruction system. For this reason, only qualitative results are shown on few images. The effects of the parameter or the discretization is not validated. The only observation made in that work is the presence of spurious edges due to noise (pg. 31), which are removed by a line fitting postprocessing.
With respect to \emph{Prewitt} and \emph{Sobel} operators, they arise from an in-depth study of different ways to discretize the gradient. In \cite{im_proc:segmentation:prewitt:1970:object_enhancement} these discretizations are discussed and compared qualitatively. In this work we tested only two of the possible discretizations, and we obtained very similar results using both operators. On the other hand, they show better performance that the \emph{Roberts} mask;

In Haralick's work, there is an interesting quantitative validation over a synthetic grid. On that evaluation, he shows results of noise sensitivity as well as comparative performance with Prewitt operators. As in this work we didn't focus on quantitative benchmarks, we didn't reproduce those results.

Regarding the Marr-Hildreth algorithm, the obtained results validate the original claims made by Marr \cite{segm:edge_region:marr:84:digital_step}, where he made the following observations:
\begin{itemize}
\item "A major difficulty with natural images is that changes can and do occur over a
wide range of scales (Marr 1976a, b). No single filter can be optimal simultaneously at all scales, so it follows that one should seek a way of dealing separately with the changes occurring at different scales. " 

\item "The reason is that strict bandlimiting gives rise to sidelobes in the spatial spatial filter, and the consequence of these is that, in the zero-crossing image, strong intensity changes give rise to echoes as well as to the directly corresponding zero-crossings..."

\item "Physical edges will produce roughly coincident zero-crossings in channels of nearby sizes. The spatial coincidence assumption asserts that the converse of this is true, that is the coincidence of zero crossings is sufficient evidence for the existence of a real physical edge. If the zero-crossings in one channel are not consistent with those in the others, they are probably caused by different physical phenomena, so descriptions need to be formed from both sources and kept somewhat separate."
\end{itemize}

The first claim is validated in our experiments by varying the $\sigma$ parameter, where we observed that no single value will allow us to obtain all the meaningful edges. The same reasoning applies to the zero crossing threshold $t_{ZC}$ .

The second observation is evidenced by the halos seen in the blades of the windmill, see inside left blade and left of the top blade in Figure \ref{fig:result3-e}. \footnote{Please look at these issues in the electronic version or the online demo, as they are not noticeable in the printed version.}

The third claim is evidenced by the structure of the saliency maps of the threshold parameter (Figures \ref{fig:results:parameters:second:saliency:a} and \ref{fig:results:parameters:second:saliency:b}) and the smoothing parameter (Figure \ref{fig:results:parameters:marr:sigma:saliency}). In both maps we observe that meaningful edges are coincident across scales and the spurious ones are not.

\renewcommand{\anchocuatro}{3.6cm}
\begin{figure*}[ht]
  \centering
\figRowMultiscaleSigma{test}{mh_th_0.15}{0002}
\figRowMultiscaleSigma{test}{mh_th_0.15}{0003}
\figRowMultiscaleSigma{test}{mh_th_0.15}{0004}
  \caption{Effect of the $\sigma$ parameter for the \textit{Marr-Hildreth} (Gaussian) algorithm on our sample images. For each example we show the original image on the left and various consecutive results with different smoothing values ($\sigma=1,2,3,4$) on the right.}
  \label{fig:results:parameters:marr:sigma}
%\vskip \espaciotabla
\end{figure*}

\renewcommand{\anchocuatro}{8cm}
\begin{figure*}[ht]
  \centering
\figRowMultiscaleH{test}{mh_th_0.15}{0002}
\figRowMultiscaleH{test}{mh_th_0.15}{0003}
\figRowMultiscaleH{test}{mh_th_0.15}{0004}
  \caption{Effect of the $\sigma$ parameter for the \textit{Marr-Hildreth} (Gaussian) algorithm on our sample images. For each example we show the original image on the left and the generated saliency map  on the right.  $\sigma$ is sampled regularly in the range $[0.5,5]$ using a step of $0.5$.}
  \label{fig:results:parameters:marr:sigma:saliency}
%\vskip \espaciotabla
\end{figure*}
%-------------------------------------------------------------------------------


\begin{comment}
\subsection{Video}

As supplementary material, there are videos testing the frame by frame application of these algorithms.

This is an example of applying the edge detection algorithms, frame by frame, to a video: 
%\begin{itemize}
%	\centering
%	\item \href{http://iie.fing.edu.uy/~haldos/ipol/video.mov}{original} (43 Mb).
%\end{itemize}
\begin{multicols}{2}
\begin{itemize}
	\item \href{http://iie.fing.edu.uy/~haldos/ipol/video.mov}{original} (43 Mb).
	\item \href{http://iie.fing.edu.uy/~haldos/ipol/video-roberts-wide_0.1.mov}{roberts version} (7.9 Mb).
	\item \href{http://iie.fing.edu.uy/~haldos/ipol/video-prewitt-wide_0.1.mov}{prewitt version} (9.1 Mb).
	\item \href{http://iie.fing.edu.uy/~haldos/ipol/video-sobel-wide_0.1.mov}{sobel version} (9.1 Mb).
	\item \href{http://iie.fing.edu.uy/~haldos/ipol/video-marr-hildreth-gaussian-wide_3_19_0.04.mov}{marr-hildreth-gaussian version} (12 Mb).
	\item \href{http://iie.fing.edu.uy/~haldos/ipol/video-marr-hildreth-log-wide_3_25_0.04.mov}{marr-hildreth-log version} (14 Mb).
	\item \href{http://iie.fing.edu.uy/~haldos/ipol/video-haralick-wide_0.5.mov}{haralick version} (12 Mb).
\end{itemize}
\end{multicols}
\end{comment}
%-------------------------------------------------------------------------------

\clearpage

%-------------------------------------------------------------------------------

\section{Conclusions}
\label{sec:conclusions}

Some of the most traditional methods of edge detection in digital images were discussed and carefully implemented in this work. The implemented algorithms were tested with synthetic and real images, obtaining generally the expected results, taking into account the limitations of these methods. 

The first derivative algorithms (Roberts, Prewitt and Sobel) have the advantage of having a very simple implementation. They also run extremely fast, because their main operation is a convolution with a very small kernel (2$\times$2 or 3$\times$3 pixels). The results obtained with these methods are quite good, considering their simplicity, but they have problems such as noise and discontinuity of the edges. Gaussian filtering would reduce noise, alleviate (but not solve) the discontinuity of the edges, and would make the comparison fairer with the second derivative methods. 

The second derivative algoritms (Marr-Hildreth \& Haralick) involve several more operations, since convolutions with larger kernels are performed. In real images, they have better behavior than first derivative algorithms. 

Comparing the two versions of the Marr-Hildreth algorithm, the version with Gaussian kernel runs significantly faster that the LoG one. The latter, while slower (since it needs a larger kernel to achieve similar results) is more accurate, because it makes no approximation to calculate the Laplacian (it is calculated analytically before creating the kernel). It is also possible to manage the size of the kernel, which represents a scale parameter of the algorithm, being able to obtain a highly detailed edge image using small kernels, or just more noticeable edges using larger kernels. \\

Haralick's algorithm, although it shares the Marr-Hildreth idea of finding zero crossings of the second derivative, has some quite different ideas. It is the only one of these algorithms which works with an approximation of the intensity of the image in the neighborhood of a pixel, using a bicubic polynomial function. This supposes a certain regularity in the image, which is not always true, and sometimes leads to detect edges where none of them exist due to ringing effects, and get some thicker edges too. 

All algorithms have their advantages and disadvantages. Choosing one or the other may depend on requirements of the application. Furthermore, we must remark that we focused on low level edge detectors, and thus none of the implemented methods ensure edge connectivity. This algorithms only serve as the input for a further edge integration step. There are many proposals in the literature aiming to integrate edgels into meaningful object boundaries. Examples of these approaches are the Canny edge detector \cite{Canny1986} or the meanignful level lines algorithm \cite{segm:cao:03:extracting_meaningful}.

With respect to the parameters, these methods require the manual determination of the parameters, and it is very hard to find a single threshold value suitable for a broad category of examples. In this sense, \emph{A contrario} methods \cite{segm:cao:03:extracting_meaningful} provide a better approach for setting parameters.
For this reason, most modern approaches use a multiscale approach, were edges are detected at many different scales and the optimum scale is chosen a posteriori, as proposed in \cite{morphology:watershed:najman:1996:geodesic_saliency} or \cite{im_proc:segmentation:arbelaez:2006:boundary_extraction}.
This idea can be even extended to pick edges at different scales depending on the region of the image (see \cite{segm:cardelino:2013:a_contrario_selection_of_optimal_partitions} for a similar idea applied to regions).

\subsection{Future work}

The goal of this work was to provide reference implementations for some of the most classical edge detectors. Some of them have been published for many years and are quite simple, however, it is surprisingly hard to find trustable implementations. We focused on low-level edge detection, which means that we do not consider post processing steps to integrate the detected edgels into meaningul lines.
Extensive qualitative validation has been performed, showing the effects of the parameters and the scale-space properties of the algorithms in order to faithfully compare them.
We consider this work as the first step towards a complete benchmark of edge detectors, which has to be completed with a systemic quantitative analysis. 
A suitable framework for this quantitative analysis is discussed and applied in \cite{segm:cardelino:2013:a_contrario_selection_of_optimal_partitions}, but this is clearly outside the scope of this work.
In particular, quantitative challenging the claims of the reviewed works will be a great contribution for the area, which is very weak with respect to experimental validation. From the original works reviewed, only Haralick presents a quantitative analysis but only over one synthetic image. Even at the moment of writing (2014), there are only a dozen edge detection and segmentation works presenting a serious quantitative analysis over a standard database of images.

%To conclude, this paper is a summary of some classical edge detection algorithms. In the preparation of this paper, no similar material (concentrated in one text) was found, so this paper appears to be useful material for whom starts studying edge detection methods. \\

%As an addendum to this work a detailed implementation of the described algorithms is presented, 
%available in C language, along with an online demo where users can run the algorithms 
%with arbitrary images uploaded by themselves.

\clearpage
\appendix
\section{Haralick convolution masks}
\newcolumntype{C}{>{\centering\arraybackslash}m{1cm}<{}}
\begin{table}[h]
\small
\centering
\subfigure[$\mathbf{mask_1}$.] {
\begin{tabular}{|*{5}{C|}}
\hline
425 & 275 & 225 & 275 & 425 \\
\hline
275 & 125 &  75 & 125 & 275 \\ 
\hline
225 &  75 &  25 &  75 & 225 \\
\hline
275 & 125 &  75 & 125 & 275 \\
\hline
425 & 275 & 225 & 275 & 425 \\
\hline
\end{tabular}}
\qquad\qquad
\subfigure[$\mathbf{mask_2}$.] {
\begin{tabular}{|*{5}{C|}}
\hline
-2260 & -620 & 0 & 620 & 2260 \\ 
\hline
-1660 & -320 & 0 & 320 & 1660 \\ 
\hline
-1460 & -220 & 0 & 220 & 1460 \\
\hline
-1660 & -320 & 0 & 320 & 1660 \\ 
\hline
-2260 & -620 & 0 & 620 & 2260 \\
\hline
\end{tabular}} \\
\subfigure[$\mathbf{mask_3}$.] {
\begin{tabular}{|*{5}{C|}}
\hline
2260  &  1660 &  1460 &  1660 &  2260 \\ 
\hline
620   &   320 &   220 &   320 &   620 \\ 
\hline
0     &     0 &     0 &     0 &     0 \\
\hline
-620  &  -320 &  -220 &  -320 &  -620 \\ 
\hline
-2260 & -1660 & -1460 & -1660 & -2260 \\
\hline
\end{tabular}}
\qquad\qquad
\subfigure[$\mathbf{mask_4}$.] {
\begin{tabular}{|*{5}{C|}}
\hline
1130 & 620 & 450 & 620 & 1130 \\ 
\hline
830  & 320 & 150 & 320 &  830 \\ 
\hline
730  & 220 &  50 & 220 &  730 \\
\hline
830  & 320 & 150 & 320 &  830 \\ 
\hline
1130 & 620 & 450 & 620 & 1130 \\
\hline
\end{tabular}} \\
\subfigure[$\mathbf{mask_5}$.] {
\begin{tabular}{|*{5}{C|}}
\hline
-400 & -200 & 0 &  200 &  400 \\ 
\hline
-200 & -100 & 0 &  100 &  200 \\ 
\hline
0    &    0 & 0 &    0 &    0 \\
\hline
200  &  100 & 0 & -100 & -200 \\ 
\hline
400  &  200 & 0 & -200 & -400 \\
\hline
\end{tabular}}
\qquad\qquad
\subfigure[$\mathbf{mask_6}$.] {
\begin{tabular}{|*{5}{C|}}
\hline
1130 & 830 & 730 & 830 & 1130 \\ 
\hline
620  & 320 & 220 & 320 &  620 \\ 
\hline
450  & 150 &  50 & 150 &  450 \\
\hline
620  & 320 & 220 & 320 &  620 \\ 
\hline
1130 & 830 & 730 & 830 & 1130 \\
\hline
\end{tabular}} \\
\subfigure[$\mathbf{mask_7}$.] {
\begin{tabular}{|*{5}{C|}}
\hline
-8260 & -2180 & 0 & 2180 & 8260 \\ 
\hline
-6220 & -1160 & 0 & 1160 & 6220 \\ 
\hline
-5540 &  -820 & 0 &  820 & 5540 \\
\hline
-6220 & -1160 & 0 & 1160 & 6220 \\ 
\hline
-8260 & -2180 & 0 & 2180 & 8260 \\
\hline
\end{tabular}}
\qquad\qquad
\subfigure[$\mathbf{mask_8}$.] {
\begin{tabular}{|*{5}{C|}}
\hline
5640  &  3600 &  2920 &  3600 &  5640 \\ 
\hline
1800  &   780 &   440 &   780 &  1800 \\ 
\hline
0     &     0 &     0 &     0 &     0 \\
\hline
-1800 &  -780 &  -440 &  -780 & -1800 \\ 
\hline
-5640 & -3600 & -2920 & -3600 & -5640 \\
\hline
\end{tabular}} \\
\subfigure[$\mathbf{mask_9}$.] {
\begin{tabular}{|*{5}{C|}}
\hline
-5640 & -1800 & 0 & 1800 & 5640 \\ 
\hline
-3600 &  -780 & 0 &  780 & 3600 \\ 
\hline
-2920 &  -440 & 0 &  440 & 2920 \\
\hline
-3600 &  -780 & 0 &  780 & 3600 \\ 
\hline
-5640 & -1800 & 0 & 1800 & 5640 \\
\hline
\end{tabular}}
\qquad\qquad
\subfigure[$\mathbf{mask_{10}}$.] {
\begin{tabular}{|*{5}{C|}}
\hline
8260  &  6220 &  5540 &  6220 &  8260 \\ 
\hline
2180  &  1160 &   820 &  1160 &  2180 \\ 
\hline
0     &     0 &     0 &     0 &     0 \\
\hline
-2180 & -1160 &  -820 & -1160 & -2180 \\ 
\hline
-8260 & -6220 & -5540 & -6220 & -8260 \\
\hline
\end{tabular}} \\
\caption{5x5 masks used to compute the coefficients of the bicubic fit.}
\label{table:b_i}
\end{table}

%-------------------------------------------------------------------------------
\clearpage
\bibliographystyle{siam}
\bibliography{journal_list_long,bibliography,references}

%-------------------------------------------------------------------------------

\end{document}

%-------------------------------------------------------------------------------


\clearpage
\section{Implementation}
\label{sec:appendix2}

In this section a detailed explanation of the source code of the different implemented algorithms
is presented. \\

To the best of our knowledge, the only freely available codes implementing this algorithms are the Matlab implementation of edge detection algorithms using 2D masks (\href{http://www.mathworks.com/help/toolbox/images/ref/edge.html}{\texttt{edge} command}) and a Haralick algorithm implementation in Matlab published in \href{http://www.mathworks.com/matlabcentral/fileexchange/35329-simple-edge-detection-using-classical-haralick-method}{Matlab Central}. There is also an implementation similar to the Marr-Hildreth algorithm, as well available in \href{http://www.mathworks.com/matlabcentral/fileexchange/11572-sdgd-edge-detection-filter}{Matlab Central}. All these links were last checked in July 2012. \\

This code documentation was generated using a perl script to extract some parts of the 
code and comments into latex files. This code documentation tool is available as a \href{https://github.com/juan-cardelino/source_comment_extractor}{GIT project}. \\

Also a Doxygen generated documentation of the functions used is available \href{http://iie.fing.edu.uy/~haldos/ipol/red_v0.1}{here}. \\

Required external libraries: 
\begin{itemize}
	\item \href{http://dev.ipol.im/git/coco/iio.git}{\texttt{iio}}.
	\item \href{http://www.libpng.org/}{\texttt{libpng}}. 
\end{itemize}

\subsection{Roberts, Prewitt and Sobel}
\input{test_fded.tex}

\subsection{Marr-Hildreth}
\label{app:marr-hildreth}
\input{test_mh.tex}

\subsection{Haralick}
\input{test_haralick.tex}

\subsection{Gaussian kernel generation}
\input{gaussian_kernel.tex}

\subsection{2D convolution}
\input{2dconvolution.tex}

%-------------------------------------------------------------------------------

